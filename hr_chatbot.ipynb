{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# âœ… Install Transformers & Hugging Face libraries\n",
        "!pip install transformers accelerate -q\n",
        "\n",
        "# ðŸ§  Imports\n",
        "from transformers import pipeline\n",
        "\n",
        "# âœ… Load a free model (T5 is lightweight and runs on CPU too)\n",
        "chatbot = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "# âœ… Define HR policy and conversation function\n",
        "def ask_bot(question, name):\n",
        "    hr_policy = \"\"\"\n",
        "    You are a helpful and friendly HR assistant. Here are the company policies:\n",
        "    - Employees are entitled to 30 days of paid annual leave.\n",
        "    - Sick leave is 15 days per year.\n",
        "    - The official work week is Sunday to Thursday.\n",
        "    - Maternity leave is 90 days.\n",
        "    - Employees can work remotely 2 days a week.\n",
        "    Answer clearly and briefly. Always greet the user by name and ask if they have more questions.\n",
        "    If they say 'no' or 'thatâ€™s all', thank them and say goodbye.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if the user wants to end the conversation\n",
        "    end_phrases = [\"no\", \"nope\", \"that's all\", \"nothing\", \"nah\"]\n",
        "    if question.lower().strip() in end_phrases:\n",
        "        return f\"ðŸ˜Š Thank you, {name}! If you need anything else, feel free to reach out. Have a great day!\"\n",
        "\n",
        "    # Main prompt template\n",
        "    prompt = f\"\"\"{hr_policy}\n",
        "\n",
        "User: Hi, my name is {name}.\n",
        "User: {question}\n",
        "HR Bot:\"\"\"\n",
        "\n",
        "    response = chatbot(prompt, max_new_tokens=150)[0]['generated_text']\n",
        "    return response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oamG6pgzNSu",
        "outputId": "892c0332-2adf-4d9c-c1fa-c0884c8e8353"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start chat\n",
        "name = input(\"ðŸ‘‹ Hello! I'm your HR assistant. Whatâ€™s your name?\\n> \")\n",
        "\n",
        "while True:\n",
        "    question = input(f\"\\n{name}, what would you like to ask?\\n> \")\n",
        "    reply = ask_bot(question, name)\n",
        "    print(\"\\nâœ… HR Bot says:\", reply)\n",
        "\n",
        "    if \"thank you\" in reply.lower():\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sbYM3pVzQEY",
        "outputId": "b87cc490-7929-4dba-a87f-19837a111249"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ‘‹ Hello! I'm your HR assistant. Whatâ€™s your name?\n",
            "> Logien\n",
            "\n",
            "Logien, what would you like to ask?\n",
            "> How many days of annual leave do I have?\n",
            "\n",
            "âœ… HR Bot says: 30 days\n",
            "\n",
            "Logien, what would you like to ask?\n",
            "> Thats all\n",
            "\n",
            "âœ… HR Bot says: Logien\n",
            "\n",
            "Logien, what would you like to ask?\n",
            "> no\n",
            "\n",
            "âœ… HR Bot says: ðŸ˜Š Thank you, Logien! If you need anything else, feel free to reach out. Have a great day!\n"
          ]
        }
      ]
    }
  ]
}